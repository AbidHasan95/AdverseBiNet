{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13419402876898417461\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ops import *\n",
    "import cv2\n",
    "import os\n",
    "from vgg import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from natsort import natsorted\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8966366955636540128\n",
      "]\n",
      "LOADING MODEL FAILED\n",
      "14\n",
      "Epoch: 0 ; Counter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## stage1 training ## : idx : 10 Dis1 loss : 4.759749 Gen1 loss : 39.735916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ; Counter: 15\n",
      "## stage1 training ## : idx : 20 Dis1 loss : 10.406568 Gen1 loss : 34.34742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from __future__ import absolute_import\n",
    "#from __future__ import division\n",
    "#from __future__ import print_function\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from ops import *\n",
    "import cv2\n",
    "import os\n",
    "from vgg import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from natsort import natsorted\n",
    "import imageio\n",
    "\n",
    "path = 'data'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "global params\n",
    "params = {'path' : path,\n",
    "          'batch_size' : 4,\n",
    "          'output_size': 256,\n",
    "          'gf_dim': 32,\n",
    "          'df_dim': 32,\n",
    "          'model_path' : './model',\n",
    "          'L1_lambda': 100,\n",
    "          'lr': 0.0001,\n",
    "          'beta_1': 0.5,\n",
    "          'epochs': 2,\n",
    "          'Img_saved_path' : 'SavedImgs',\n",
    "          'Img_saved_path_for_real_data' : 'SavedReal',\n",
    "          'Stage_epochs' : [10000,20000]}\n",
    "\n",
    "if not os.path.isdir(params['Img_saved_path']):\n",
    "    os.mkdir(params['Img_saved_path'])\n",
    "\n",
    "if not os.path.isdir(params['Img_saved_path_for_real_data']):\n",
    "    os.mkdir(params['Img_saved_path_for_real_data'])\n",
    "\n",
    "def get_file_paths(path):\n",
    "    img_paths = [os.path.join(root, file)  for root, dirs, files in os.walk(path) for file in files if '_gt' not in file]\n",
    "    gt_path = [os.path.join(os.path.dirname(file), os.path.basename(file).split('.')[0] + '_est_gt.tiff') for file in img_paths]\n",
    "    return np.array(img_paths[:int(len(img_paths)*.9)]), np.array(gt_path[:int(len(gt_path)*.9)]), np.array(img_paths[int(len(img_paths)*.9):])        , np.array(gt_path[int(len(gt_path)*.9):])\n",
    "\n",
    "\n",
    "def load_data_CONTENT(path):\n",
    "    im = ~cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (256, 256))\n",
    "    return np.expand_dims(im, -1)/127.5 - 1.\n",
    "\n",
    "def load_data(path):\n",
    "    im = cv2.resize(cv2.imread(path, 0), (256, 256))\n",
    "    return  np.expand_dims(im, -1)/127.5 - 1.\n",
    "\n",
    "# Functions to load and save weights\n",
    "def load_weights(saver, model_dir):\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(model_dir, ckpt_name))\n",
    "        print(\"MODEL LOADED SUCCESSFULLY\")\n",
    "    else:\n",
    "        print(\"LOADING MODEL FAILED\")\n",
    "\n",
    "def save(saver, checkpoint_dir, step):\n",
    "    dir = os.path.join(checkpoint_dir, \"model\")\n",
    "    saver.save(sess, dir, step)\n",
    "\n",
    "\n",
    "global g_bn_d1, g_bn_d2, g_bn_d3, g_bn_d4, g_bn_d5, g_bn_d6, g_bn_d7\n",
    "\n",
    "d_bn1 = batch_norm(name='d_bn1')\n",
    "d_bn2 = batch_norm(name='d_bn2')\n",
    "d_bn3 = batch_norm(name='d_bn3')\n",
    "\n",
    "g_bn_e2 = batch_norm(name='g_bn_e2')\n",
    "g_bn_e3 = batch_norm(name='g_bn_e3')\n",
    "g_bn_e4 = batch_norm(name='g_bn_e4')\n",
    "g_bn_e5 = batch_norm(name='g_bn_e5')\n",
    "g_bn_e6 = batch_norm(name='g_bn_e6')\n",
    "g_bn_e7 = batch_norm(name='g_bn_e7')\n",
    "g_bn_e8 = batch_norm(name='g_bn_e8')\n",
    "\n",
    "g_bn_d1 = batch_norm(name='g_bn_d1')\n",
    "g_bn_d2 = batch_norm(name='g_bn_d2')\n",
    "g_bn_d3 = batch_norm(name='g_bn_d3')\n",
    "g_bn_d4 = batch_norm(name='g_bn_d4')\n",
    "g_bn_d5 = batch_norm(name='g_bn_d5')\n",
    "g_bn_d6 = batch_norm(name='g_bn_d6')\n",
    "g_bn_d7 = batch_norm(name='g_bn_d7')\n",
    "\n",
    "\n",
    "global g_bn_d1_, g_bn_d2_, g_bn_d3_, g_bn_d4_, g_bn_d5_, g_bn_d6_, g_bn_d7_\n",
    "\n",
    "\n",
    "global d_bn1_, d_bn2_, d_bn3_\n",
    "d_bn1_ = batch_norm(name='d_bn1_')\n",
    "d_bn2_ = batch_norm(name='d_bn2_')\n",
    "d_bn3_ = batch_norm(name='d_bn3_')\n",
    "\n",
    "g_bn_e2_ = batch_norm(name='g_bn_e2_')\n",
    "g_bn_e3_ = batch_norm(name='g_bn_e3_')\n",
    "g_bn_e4_ = batch_norm(name='g_bn_e4_')\n",
    "g_bn_e5_ = batch_norm(name='g_bn_e5_')\n",
    "g_bn_e6_ = batch_norm(name='g_bn_e6_')\n",
    "g_bn_e7_ = batch_norm(name='g_bn_e7_')\n",
    "g_bn_e8_ = batch_norm(name='g_bn_e8_')\n",
    "\n",
    "g_bn_d1_ = batch_norm(name='g_bn_d1_')\n",
    "g_bn_d2_ = batch_norm(name='g_bn_d2_')\n",
    "g_bn_d3_ = batch_norm(name='g_bn_d3_')\n",
    "g_bn_d4_ = batch_norm(name='g_bn_d4_')\n",
    "g_bn_d5_ = batch_norm(name='g_bn_d5_')\n",
    "g_bn_d6_ = batch_norm(name='g_bn_d6_')\n",
    "g_bn_d7_ = batch_norm(name='g_bn_d7_')\n",
    "\n",
    "\n",
    "def Noise_transfer_network(content, style, y=None):\n",
    "    s = params['output_size']\n",
    "    output_c_dim = 1\n",
    "    s2, s4, s8, s16, s32, s64, s128 = int(s/2), int(s/4), int(s/8), int(s/16), int(s/32), int(s/64), int(s/128)\n",
    "    gf_dim = params['gf_dim']\n",
    "\n",
    "\n",
    "    with tf.variable_scope(\"generator1\") as globscope:\n",
    "\n",
    "        with tf.variable_scope(\"content_encoder\") as scope:\n",
    "\n",
    "            # image is (256 x 256 x input_c_dim)\n",
    "            c_e1 = conv2d(content, gf_dim, name='g_e1_conv')\n",
    "            # e1 is (128 x 128 x gf_dim)\n",
    "            c_e2 = g_bn_e2(conv2d(lrelu(c_e1), gf_dim*2, name='g_e2_conv'))\n",
    "            # e2 is (64 x 64 x gf_dim*2)\n",
    "            c_e3 = g_bn_e3(conv2d(lrelu(c_e2), gf_dim*4, name='g_e3_conv'))\n",
    "            # e3 is (32 x 32 x gf_dim*4)\n",
    "            c_e4 = g_bn_e4(conv2d(lrelu(c_e3), gf_dim*8, name='g_e4_conv'))\n",
    "            # e4 is (16 x 16 x gf_dim*8)\n",
    "            c_e5 = g_bn_e5(conv2d(lrelu(c_e4), gf_dim*8, name='g_e5_conv'))\n",
    "            # e5 is (8 x 8 x gf_dim*8)\n",
    "            c_e6 = g_bn_e6(conv2d(lrelu(c_e5), gf_dim*8, name='g_e6_conv'))\n",
    "            # e6 is (4 x 4 x gf_dim*8)\n",
    "            c_e7 = g_bn_e7(conv2d(lrelu(c_e6), gf_dim*8, name='g_e7_conv'))\n",
    "            # e7 is (2 x 2 x gf_dim*8)\n",
    "            c_e8 = g_bn_e8(conv2d(lrelu(c_e7), gf_dim*8, name='g_e8_conv'))\n",
    "            # e8 is (1 x 1 x gf_dim*8)\n",
    "\n",
    "        with tf.variable_scope(\"style_encoder\") as scope:\n",
    "\n",
    "            # image is (256 x 256 x input_c_dim)\n",
    "            s_e1 = conv2d(style, gf_dim, name='g_e1_conv')\n",
    "            # e1 is (128 x 128 x gf_dim)\n",
    "            s_e2 = g_bn_e2(conv2d(lrelu(s_e1), gf_dim*2, name='g_e2_conv'))\n",
    "            # e2 is (64 x 64 x gf_dim*2)\n",
    "            s_e3 = g_bn_e3(conv2d(lrelu(s_e2), gf_dim*4, name='g_e3_conv'))\n",
    "            # e3 is (32 x 32 x gf_dim*4)\n",
    "            s_e4 = g_bn_e4(conv2d(lrelu(s_e3), gf_dim*8, name='g_e4_conv'))\n",
    "            # e4 is (16 x 16 x gf_dim*8)\n",
    "            s_e5 = g_bn_e5(conv2d(lrelu(s_e4), gf_dim*8, name='g_e5_conv'))\n",
    "            # e5 is (8 x 8 x gf_dim*8)\n",
    "            s_e6 = g_bn_e6(conv2d(lrelu(s_e5), gf_dim*8, name='g_e6_conv'))\n",
    "            # e6 is (4 x 4 x gf_dim*8)\n",
    "            s_e7 = g_bn_e7(conv2d(lrelu(s_e6), gf_dim*8, name='g_e7_conv'))\n",
    "            # e7 is (2 x 2 x gf_dim*8)\n",
    "            s_e8 = g_bn_e8(conv2d(lrelu(s_e7), gf_dim*8, name='g_e8_conv'))\n",
    "\n",
    "        m_e8 = tf.concat([c_e8, s_e8],-1)\n",
    "\n",
    "        with tf.variable_scope(\"decoder\") as scope:\n",
    "\n",
    "            batch_size = params['batch_size']\n",
    "            d1, d1_w, d1_b = deconv2d(tf.nn.relu(m_e8),\n",
    "                [batch_size, s128, s128, gf_dim*8], name='g_d1', with_w=True)\n",
    "            d1 = tf.nn.dropout(g_bn_d1(d1), 0.5)\n",
    "            d1 = tf.concat([d1, c_e7], 3)\n",
    "            # d1 is (2 x 2 x gf_dim*8*2)\n",
    "\n",
    "            d2, d2_w, d2_b = deconv2d(tf.nn.relu(d1),\n",
    "                [batch_size, s64, s64, gf_dim*8], name='g_d2', with_w=True)\n",
    "            d2 = tf.nn.dropout(g_bn_d2(d2), 0.5)\n",
    "            d2 = tf.concat([d2, c_e6], 3)\n",
    "            # d2 is (4 x 4 x gf_dim*8*2)\n",
    "\n",
    "            d3, d3_w, d3_b = deconv2d(tf.nn.relu(d2),\n",
    "                [batch_size, s32, s32, gf_dim*8], name='g_d3', with_w=True)\n",
    "            d3 = tf.nn.dropout(g_bn_d3(d3), 0.5)\n",
    "            d3 = tf.concat([d3, c_e5], 3)\n",
    "            # d3 is (8 x 8 x gf_dim*8*2)\n",
    "\n",
    "            d4, d4_w, d4_b = deconv2d(tf.nn.relu(d3),\n",
    "                [batch_size, s16, s16, gf_dim*8], name='g_d4', with_w=True)\n",
    "            d4 = g_bn_d4(d4)\n",
    "            d4 = tf.concat([d4, c_e4], 3)\n",
    "            # d4 is (16 x 16 x gf_dim*8*2)\n",
    "\n",
    "            d5, d5_w, d5_b = deconv2d(tf.nn.relu(d4),\n",
    "                [batch_size, s8, s8, gf_dim*4], name='g_d5', with_w=True)\n",
    "            d5 = g_bn_d5(d5)\n",
    "            d5 = tf.concat([d5, c_e3], 3)\n",
    "            # d5 is (32 x 32 x gf_dim*4*2)\n",
    "\n",
    "            d6, d6_w, sd6_b = deconv2d(tf.nn.relu(d5),\n",
    "                [batch_size, s4, s4, gf_dim*2], name='g_d6', with_w=True)\n",
    "            d6 = g_bn_d6(d6)\n",
    "            d6 = tf.concat([d6, c_e2], 3)\n",
    "            # d6 is (64 x 64 x gf_dim*2*2)\n",
    "\n",
    "            d7, d7_w, d7_b = deconv2d(tf.nn.relu(d6),\n",
    "                [batch_size, s2, s2, gf_dim], name='g_d7', with_w=True)\n",
    "            d7 = g_bn_d7(d7)\n",
    "            d7 = tf.concat([d7, c_e1], 3)\n",
    "            # d7 is (128 x 128 x gf_dim*1*2)\n",
    "\n",
    "            d8, d8_w, d8_b = deconv2d(tf.nn.relu(d7),\n",
    "                [batch_size, s, s, output_c_dim], name='g_d8', with_w=True)\n",
    "            # d8 is (256 x 256 x output_c_dim)\n",
    "\n",
    "        return tf.nn.tanh(d8)\n",
    "\n",
    "\n",
    "\n",
    "def Noise_remover_network(image, y=None):\n",
    "\n",
    "    s = params['output_size']\n",
    "    output_c_dim = 1\n",
    "    s2, s4, s8, s16, s32, s64, s128 = int(s/2), int(s/4), int(s/8), int(s/16), int(s/32), int(s/64), int(s/128)\n",
    "    gf_dim = params['gf_dim']\n",
    "\n",
    "    with tf.variable_scope(\"generator2\", reuse = tf.AUTO_REUSE) as scope:\n",
    "\n",
    "        # image is (256 x 256 x input_c_dim)\n",
    "        e1 = conv2d(image, gf_dim, name='g_e1_conv')\n",
    "        # e1 is (128 x 128 x gf_dim)\n",
    "        e2 = g_bn_e2_(conv2d(lrelu(e1), gf_dim*2, name='g_e2_conv'))\n",
    "        # e2 is (64 x 64 x gf_dim*2)\n",
    "        e3 = g_bn_e3_(conv2d(lrelu(e2), gf_dim*4, name='g_e3_conv'))\n",
    "        # e3 is (32 x 32 x gf_dim*4)\n",
    "        e4 = g_bn_e4_(conv2d(lrelu(e3), gf_dim*8, name='g_e4_conv'))\n",
    "        # e4 is (16 x 16 x gf_dim*8)\n",
    "        e5 = g_bn_e5_(conv2d(lrelu(e4), gf_dim*8, name='g_e5_conv'))\n",
    "        # e5 is (8 x 8 x gf_dim*8)\n",
    "        e6 = g_bn_e6_(conv2d(lrelu(e5), gf_dim*8, name='g_e6_conv'))\n",
    "        # e6 is (4 x 4 x gf_dim*8)\n",
    "        e7 = g_bn_e7_(conv2d(lrelu(e6), gf_dim*8, name='g_e7_conv'))\n",
    "        # e7 is (2 x 2 x gf_dim*8)\n",
    "        e8 = g_bn_e8_(conv2d(lrelu(e7), gf_dim*8, name='g_e8_conv'))\n",
    "        # e8 is (1 x 1 x gf_dim*8)\n",
    "\n",
    "        batch_size = params['batch_size']\n",
    "        d1, d1_w, d1_b = deconv2d(tf.nn.relu(e8),\n",
    "            [batch_size, s128, s128, gf_dim*8], name='g_d1', with_w=True)\n",
    "        d1 = tf.nn.dropout(g_bn_d1_(d1), 0.5)\n",
    "        d1 = tf.concat([d1, e7], 3)\n",
    "        # d1 is (2 x 2 x gf_dim*8*2)\n",
    "\n",
    "        d2, d2_w, d2_b = deconv2d(tf.nn.relu(d1),\n",
    "            [batch_size, s64, s64, gf_dim*8], name='g_d2', with_w=True)\n",
    "        d2 = tf.nn.dropout(g_bn_d2_(d2), 0.5)\n",
    "        d2 = tf.concat([d2, e6], 3)\n",
    "        # d2 is (4 x 4 x gf_dim*8*2)\n",
    "\n",
    "        d3, d3_w, d3_b = deconv2d(tf.nn.relu(d2),\n",
    "            [batch_size, s32, s32, gf_dim*8], name='g_d3', with_w=True)\n",
    "        d3 = tf.nn.dropout(g_bn_d3_(d3), 0.5)\n",
    "        d3 = tf.concat([d3, e5], 3)\n",
    "        # d3 is (8 x 8 x gf_dim*8*2)\n",
    "\n",
    "        d4, d4_w, d4_b = deconv2d(tf.nn.relu(d3),\n",
    "            [batch_size, s16, s16, gf_dim*8], name='g_d4', with_w=True)\n",
    "        d4 = g_bn_d4_(d4)\n",
    "        d4 = tf.concat([d4, e4], 3)\n",
    "        # d4 is (16 x 16 x gf_dim*8*2)\n",
    "\n",
    "        d5, d5_w, d5_b = deconv2d(tf.nn.relu(d4),\n",
    "            [batch_size, s8, s8, gf_dim*4], name='g_d5', with_w=True)\n",
    "        d5 = g_bn_d5_(d5)\n",
    "        d5 = tf.concat([d5, e3], 3)\n",
    "        # d5 is (32 x 32 x gf_dim*4*2)\n",
    "\n",
    "        d6, d6_w, sd6_b = deconv2d(tf.nn.relu(d5),\n",
    "            [batch_size, s4, s4, gf_dim*2], name='g_d6', with_w=True)\n",
    "        d6 = g_bn_d6_(d6)\n",
    "        d6 = tf.concat([d6, e2], 3)\n",
    "        # d6 is (64 x 64 x gf_dim*2*2)\n",
    "\n",
    "        d7, d7_w, d7_b = deconv2d(tf.nn.relu(d6),\n",
    "            [batch_size, s2, s2, gf_dim], name='g_d7', with_w=True)\n",
    "        d7 = g_bn_d7_(d7)\n",
    "        d7 = tf.concat([d7, e1], 3)\n",
    "        # d7 is (128 x 128 x gf_dim*1*2)\n",
    "\n",
    "        d8, d8_w, d8_b = deconv2d(tf.nn.relu(d7),\n",
    "            [batch_size, s, s, output_c_dim], name='g_d8', with_w=True)\n",
    "        # d8 is (256 x 256 x output_c_dim)\n",
    "\n",
    "        #return tf.nn.tanh(d8[:,:,:,:3]), tf.nn.tanh(d8[:,:,:,3:4])  #(w/o text , bin text)\n",
    "        return tf.nn.tanh(d8)\n",
    "\n",
    "\n",
    "\n",
    "def discriminator1(image, y=None, reuse=False):\n",
    "\n",
    "    df_dim = params['df_dim']\n",
    "    batch_size = params['batch_size']\n",
    "    with tf.variable_scope(\"discriminator1\") as scope:\n",
    "\n",
    "        # image is 256 x 256 x (input_c_dim + output_c_dim)\n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse == False\n",
    "\n",
    "        h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
    "        # h0 is (128 x 128 x df_dim)\n",
    "        h1 = lrelu(d_bn1(conv2d(h0, df_dim*2, name='d_h1_conv')))\n",
    "        # h1 is (64 x 64 x df_dim*2)\n",
    "        h2 = lrelu(d_bn2(conv2d(h1, df_dim*4, name='d_h2_conv')))\n",
    "        # h2 is (32x 32 x df_dim*4)\n",
    "        h3 = lrelu(d_bn3(conv2d(h2, df_dim*8, d_h=1, d_w=1, name='d_h3_conv')))\n",
    "        # h3 is (16 x 16 x df_dim*8)\n",
    "        h4 = linear(tf.reshape(h3, [batch_size, -1]), 1, 'd_h3_lin')\n",
    "\n",
    "        return tf.nn.sigmoid(h4), h4\n",
    "\n",
    "\n",
    "def discriminator2(image, y=None, reuse=False):\n",
    "    df_dim = params['df_dim']\n",
    "    batch_size = params['batch_size']\n",
    "    with tf.variable_scope(\"discriminator2\") as scope:\n",
    "\n",
    "        # image is 256 x 256 x (input_c_dim + output_c_dim)\n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        else:\n",
    "            assert tf.get_variable_scope().reuse == False\n",
    "\n",
    "        h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
    "        # h0 is (128 x 128 x df_dim)\n",
    "        h1 = lrelu(d_bn1(conv2d(h0, df_dim * 2, name='d_h1_conv')))\n",
    "        # h1 is (64 x 64 x df_dim*2)\n",
    "        h2 = lrelu(d_bn2(conv2d(h1, df_dim * 4, name='d_h2_conv')))\n",
    "        # h2 is (32x 32 x df_dim*4)\n",
    "        h3 = lrelu(d_bn3(conv2d(h2, df_dim * 8, d_h=1, d_w=1, name='d_h3_conv')))\n",
    "        # h3 is (16 x 16 x df_dim*8)\n",
    "        h4 = linear(tf.reshape(h3, [batch_size, -1]), 1, 'd_h3_lin')\n",
    "\n",
    "        return tf.nn.sigmoid(h4), h4\n",
    "\n",
    "\n",
    "def get_content_loss(output, content):\n",
    "\n",
    "    #tf.summary.image('mask', (1 - content),  max_outputs=1)\n",
    "\n",
    "    #output = (output+1)/2\n",
    "\n",
    "    masked_ = (1 - content) * tf.square(output - content)\n",
    "\n",
    "    #masked_ = (1 - content) * output\n",
    "    #tf.summary.image('masked', masked_, max_outputs=1)\n",
    "\n",
    "    return tf.reduce_mean(masked_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_style_loss(output, style):\n",
    "\n",
    "    style = (tf.image.grayscale_to_rgb(style)+1)/2\n",
    "\n",
    "    output = (tf.image.grayscale_to_rgb(output)+1)/2\n",
    "\n",
    "    data_dict = loadWeightsData('./vgg16.npy')\n",
    "\n",
    "    def gram_matrix(x):\n",
    "        assert isinstance(x, tf.Tensor)\n",
    "        b, h, w, ch = x.get_shape().as_list()\n",
    "        features = tf.reshape(x, [b, h*w, ch])\n",
    "        # gram = tf.batch_matmul(features, features, adj_x=True)/tf.constant(ch*w*h, tf.float32)\n",
    "        gram = tf.matmul(features, features, adjoint_a=True)/tf.constant(ch*w*h, tf.float32)\n",
    "        return gram\n",
    "\n",
    "    vgg_o = custom_Vgg16(output, data_dict=data_dict)\n",
    "    feature_o = [vgg_o.conv1_2, vgg_o.conv2_2, vgg_o.conv3_3, vgg_o.conv4_3, vgg_o.conv5_3]\n",
    "    gram_o = [gram_matrix(l) for l in feature_o]\n",
    "    vgg_s = custom_Vgg16(style, data_dict=data_dict)\n",
    "    feature_s = [vgg_s.conv1_2, vgg_s.conv2_2, vgg_s.conv3_3, vgg_s.conv4_3, vgg_s.conv5_3]\n",
    "    gram_s = [gram_matrix(l) for l in feature_s]\n",
    "    loss_s = tf.zeros(params['batch_size'], tf.float32)\n",
    "    for g, g_ in zip(gram_o, gram_s):\n",
    "        loss_s += tf.reduce_mean(tf.subtract(g, g_) ** 2, [1, 2])\n",
    "\n",
    "    return tf.reduce_mean(loss_s)\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "global sess\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "content = tf.placeholder(dtype=tf.float32, shape=[params['batch_size'],256,256,1], name = 'content')\n",
    "style = tf.placeholder(dtype=tf.float32, shape=[params['batch_size'],256,256,1], name = 'style')\n",
    "Real_input = tf.placeholder(dtype=tf.float32, shape=[params['batch_size'],256,256,1], name = 'Real_input')\n",
    "\n",
    "output = Noise_transfer_network(content, style)\n",
    "\n",
    "Cleaned = Noise_remover_network(output)\n",
    "\n",
    "# For testing\n",
    "Real_cleaned = Noise_remover_network(Real_input)\n",
    "\n",
    "tf.summary.image(\"Content_Image\", content, max_outputs=1)\n",
    "tf.summary.image(\"Style_Image\", style, max_outputs=1)\n",
    "tf.summary.image(\"Generated_Noise\", output, max_outputs=1)\n",
    "tf.summary.image(\"Cleaned_output\", Cleaned, max_outputs=1)\n",
    "\n",
    "## stage1 losses\n",
    "\n",
    "D1_real,D1_real_logits = discriminator1(style, reuse=False)\n",
    "D1_fake,D1_fake_logits = discriminator1(output, reuse=True)\n",
    "\n",
    "d1_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_real_logits, labels=tf.ones_like(D1_real)))\n",
    "d1_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_fake_logits, labels=tf.zeros_like(D1_fake)))\n",
    "d1_loss = d1_loss_real + d1_loss_fake\n",
    "g1_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_fake_logits, labels=tf.ones_like(D1_fake)))\n",
    "\n",
    "content_loss = get_content_loss(output, content)\n",
    "style_loss = get_style_loss(output, style)\n",
    "\n",
    "g1_loss = g1_loss + 10*content_loss + 0.5*style_loss\n",
    "\n",
    "## stage2 losses\n",
    "\n",
    "D2_real,D2_real_logits = discriminator2(content, reuse=False)\n",
    "D2_fake,D2_fake_logits = discriminator2(Cleaned, reuse=True)\n",
    "\n",
    "d2_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_real_logits, labels=tf.ones_like(D2_real)))\n",
    "d2_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_fake_logits, labels=tf.zeros_like(D2_fake)))\n",
    "d2_loss = d2_loss_real + d2_loss_fake\n",
    "g2_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_fake_logits, labels=tf.ones_like(D2_fake)))\n",
    "\n",
    "g2_loss = g2_loss + 100 * tf.reduce_mean(tf.abs(content - Cleaned))\n",
    "\n",
    "## Combined stage1 & stage2 loss\n",
    "\n",
    "g1_loss_e2e = g1_loss\n",
    "d1_loss_e2e = d1_loss\n",
    "\n",
    "g2_loss_e2e = g2_loss\n",
    "d2_loss_e2e = d2_loss\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "g1_vars = [var for var in t_vars if 'generator1' in var.name]\n",
    "g2_vars = [var for var in t_vars if 'generator2' in var.name]\n",
    "\n",
    "d1_vars = [var for var in t_vars if 'discriminator1' in var.name]\n",
    "d2_vars = [var for var in t_vars if 'discriminator2' in var.name]\n",
    "\n",
    "\n",
    "d1_optim = tf.train.AdamOptimizer(params['lr'], beta1=params['beta_1'])\n",
    "g1_optim = tf.train.AdamOptimizer(params['lr'], beta1=params['beta_1'])\n",
    "d2_optim = tf.train.AdamOptimizer(params['lr'], beta1=params['beta_1'])\n",
    "g2_optim = tf.train.AdamOptimizer(params['lr'], beta1=params['beta_1'])\n",
    "\n",
    "\n",
    "# stage1 training\n",
    "\n",
    "d1_grads = tf.gradients(d1_loss, d1_vars)\n",
    "d1_train = d1_optim.apply_gradients(zip(d1_grads, d1_vars))\n",
    "\n",
    "g1_grads = tf.gradients(g1_loss, g1_vars)\n",
    "g1_train = g1_optim.apply_gradients(zip(g1_grads, g1_vars))\n",
    "\n",
    "# stage2 training\n",
    "\n",
    "d2_grads = tf.gradients(d2_loss, d2_vars)\n",
    "d2_train = d2_optim.apply_gradients(zip(d2_grads, d2_vars))\n",
    "\n",
    "g2_grads = tf.gradients(g2_loss, g2_vars)\n",
    "g2_train = g2_optim.apply_gradients(zip(g2_grads, g2_vars))\n",
    "\n",
    "# Combined training\n",
    "\n",
    "d1_grads_e2e = tf.gradients(d1_loss_e2e, d1_vars)\n",
    "d1_train_e2e = d1_optim.apply_gradients(zip(d1_grads_e2e, d1_vars))\n",
    "\n",
    "g1_grads_e2e = tf.gradients(g1_loss_e2e, g1_vars)\n",
    "g1_train_e2e = g1_optim.apply_gradients(zip(g1_grads_e2e, g1_vars))\n",
    "\n",
    "d2_grads_e2e = tf.gradients(d2_loss_e2e, d2_vars)\n",
    "d2_train_e2e = d2_optim.apply_gradients(zip(d2_grads_e2e, d2_vars))\n",
    "\n",
    "g2_grads_e2e = tf.gradients(g2_loss_e2e, g2_vars)\n",
    "g2_train_e2e = g2_optim.apply_gradients(zip(g2_grads_e2e, g2_vars))\n",
    "\n",
    "\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "load_weights(saver, params['model_path'])\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "trainwriter = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "\n",
    "counter = 1\n",
    "start_time = time.time()\n",
    "train_STYLEpath, train_CONTENTpath, test_STYLEpath, test_CONTENTpath = get_file_paths(params['path'])\n",
    "\n",
    "np.random.shuffle(train_STYLEpath)\n",
    "np.random.shuffle(train_CONTENTpath)\n",
    "\n",
    "data_set_size = len(train_STYLEpath)\n",
    "\n",
    "print (data_set_size//params['batch_size'])\n",
    "\n",
    "rndm_test_style = test_STYLEpath[np.random.choice(len(test_STYLEpath),params['batch_size']*2)]\n",
    "rndm_test_content = test_CONTENTpath[np.random.choice(len(test_CONTENTpath),params['batch_size']*2)]\n",
    "\n",
    "Fixd_rndm_indx = np.random.choice(len(test_STYLEpath),params['batch_size']*2)\n",
    "\n",
    "paired_smaple_input = test_STYLEpath[Fixd_rndm_indx]\n",
    "paired_smaple_output = test_CONTENTpath[Fixd_rndm_indx]\n",
    "\n",
    "myVar = []\n",
    "for epoch in range(params['epochs']):\n",
    "\n",
    "    print(\"Epoch: {} ; Counter: {}\".format(epoch, counter))\n",
    "\n",
    "    for idx in range(data_set_size//params['batch_size']):\n",
    "\n",
    "        batch_STYLEpath = train_STYLEpath[idx * params['batch_size'] : (idx + 1) * params['batch_size']]\n",
    "        batch_STYLEdata = np.array([load_data(path) for path in batch_STYLEpath])\n",
    "        batch_CONTENTpath = train_CONTENTpath[idx * params['batch_size']: (idx + 1) * params['batch_size']]\n",
    "        batch_CONTENTdata = np.array([load_data_CONTENT(path) for path in batch_CONTENTpath])\n",
    "\n",
    "        feed_dict = {content : batch_CONTENTdata , style : batch_STYLEdata}\n",
    "\n",
    "\n",
    "        if counter<=params['Stage_epochs'][0]:\n",
    "\n",
    "            ## stage1 training\n",
    "            _, d1_loss_ = sess.run([d1_train, d1_loss], feed_dict) # update D1 network\n",
    "            _, g1_loss_ = sess.run([g1_train, g1_loss], feed_dict) # update G1 network\n",
    "            _,summary_, g1_loss_ = sess.run([g1_train,summary, g1_loss], feed_dict) # update G1 network\n",
    "\n",
    "            if counter%10 == 0:\n",
    "\n",
    "                print ('## stage1 training ## : idx : ' +str(counter) + ' Dis1 loss : '+str(d1_loss_) + ' Gen1 loss : '+str(g1_loss_))\n",
    "\n",
    "        elif counter>params['Stage_epochs'][0] and counter<=params['Stage_epochs'][1]:\n",
    "\n",
    "\n",
    "            ## stage2 training\n",
    "            _, d2_loss_ = sess.run([d2_train, d2_loss], feed_dict) # update D2 network\n",
    "            _, g2_loss_ = sess.run([g2_train, g2_loss], feed_dict) # update G2 network\n",
    "            _,summary_, g2_loss_ = sess.run([g2_train,summary, g2_loss], feed_dict) # update G2 network\n",
    "\n",
    "            if counter%10 == 0:\n",
    "\n",
    "                print ('## stage2 training ## : idx : ' +str(counter) + ' Dis2 loss : '+str(d2_loss_) + ' Gen2 loss : '+str(g2_loss_))\n",
    "\n",
    "        else:\n",
    "\n",
    "            ## combined training\n",
    "            _, d1_loss_e2e_ = sess.run([d1_train_e2e, d1_loss], feed_dict) # update D1 network\n",
    "            _, g1_loss_e2e_ = sess.run([g1_train_e2e, g1_loss], feed_dict) # update G1 network\n",
    "            _,summary_, g1_loss_e2e_ = sess.run([g1_train_e2e, summary, g1_loss], feed_dict) # update G1 network\n",
    "\n",
    "            _, d2_loss_e2e_ = sess.run([d2_train_e2e, d2_loss], feed_dict) # update D1 network\n",
    "            _, g2_loss_e2e_ = sess.run([g2_train_e2e, g2_loss], feed_dict) # update G1 network\n",
    "            _,summary_, g2_loss_e2e_ = sess.run([g2_train_e2e, summary, g2_loss], feed_dict) # update G1 network\n",
    "\n",
    "            if counter%10 == 0:\n",
    "\n",
    "                print ('## Combined training ## : idx : ' +str(counter) + ' Dis1 loss : '+str(d1_loss_e2e_) + ' Gen1 loss : '+str(g1_loss_e2e_)+ ' Dis2 loss : '+str(d2_loss_e2e_) + ' Gen2 loss : '+str(g2_loss_e2e_))\n",
    "\n",
    "        trainwriter.add_summary(summary_, counter)\n",
    "\n",
    "\n",
    "\n",
    "        if counter<=10:\n",
    "\n",
    "\n",
    "\n",
    "            if not os.path.isdir(os.path.join(params['Img_saved_path'], str(counter))):\n",
    "                os.mkdir(os.path.join(params['Img_saved_path'], str(counter)))\n",
    "\n",
    "            if not os.path.isdir(os.path.join(params['Img_saved_path_for_real_data'], str(counter))):\n",
    "                os.mkdir(os.path.join(params['Img_saved_path_for_real_data'], str(counter)))\n",
    "\n",
    "            cc = 1\n",
    "\n",
    "            for k in range(2):\n",
    "\n",
    "                batchx = paired_smaple_input[k * params['batch_size'] : (k + 1) * params['batch_size']]\n",
    "                batchx_data = np.array([load_data(path) for path in batchx])\n",
    "                batchy = paired_smaple_output[k * params['batch_size'] : (k + 1) * params['batch_size']]\n",
    "                batchy_data = np.array([load_data_CONTENT(path) for path in batchy])\n",
    "\n",
    "                feed_dict = {Real_input : batchx_data}\n",
    "\n",
    "                Real_cleaned_ = sess.run(Real_cleaned, feed_dict)\n",
    "\n",
    "                all_imgs = np.concatenate((batchx_data, batchy_data, Real_cleaned_),2)\n",
    "                myVar.append(all_imgs)\n",
    "                for no_i in range(params['batch_size']):\n",
    "\n",
    "                    imageio.imwrite(os.path.join(params['Img_saved_path_for_real_data'], str(counter), str(cc) + \".png\"), all_imgs[no_i,:,:,:])\n",
    "\n",
    "                    cc = cc + 1\n",
    "\n",
    "            cc = 1\n",
    "\n",
    "            for k in range(2):\n",
    "\n",
    "                batch_STYLEpath = rndm_test_style[k * params['batch_size'] : (k + 1) * params['batch_size']]\n",
    "                batch_STYLEdata = np.array([load_data(path) for path in batch_STYLEpath])\n",
    "                batch_CONTENTpath = rndm_test_content[k * params['batch_size']: (k + 1) * params['batch_size']]\n",
    "                batch_CONTENTdata = np.array([load_data_CONTENT(path) for path in batch_CONTENTpath])\n",
    "\n",
    "                feed_dict = {content : batch_CONTENTdata , style : batch_STYLEdata}\n",
    "\n",
    "                _cleaned, _output = sess.run([Cleaned, output], feed_dict)\n",
    "\n",
    "                all_imgs = np.concatenate((batch_CONTENTdata, batch_STYLEdata, _output, _cleaned),2)\n",
    "                myVar.append(all_imgs)\n",
    "                for no_i in range(params['batch_size']):\n",
    "\n",
    "                    imageio.imwrite(os.path.join(params['Img_saved_path'], str(counter), str(cc) + \".png\"), all_imgs[no_i,:,:,:])\n",
    "\n",
    "                    cc = cc + 1\n",
    "\n",
    "        counter = counter + 1\n",
    "        if counter>= 200:\n",
    "            save(saver, params['model_path'], counter)\n",
    "            print('Model Saved!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imwrite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 768, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVar[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data2\\\\1.jpg'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path,str(1)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('image0021_gt.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361, 888)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imwrite('abcd.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.expand_dims(img, -1)/127.5 - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [-1.0, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "imageio.imwrite('abcd2.jpg',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361, 888, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
